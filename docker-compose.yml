services:
  app:
    image: p6
    ports:
    - "127.0.0.1:5000:5000"
    - "127.0.0.1:4040:4040"
    volumes:
    - "./nb:/notebooks"
    entrypoint: ["python3", "-m", "jupyterlab", "--no-browser", "--ip=0.0.0.0", "--port=5000", "--allow-root", "--NotebookApp.token=''"]

  nn:
    image: p6
    entrypoint: ["sh", "-c", "hdfs namenode -format -force; hdfs namenode -fs hdfs://nn:9000"]

  dn:
    image: p6
    entrypoint: ["hdfs", "datanode", "-fs", "hdfs://nn:9000"]

  spark-boss:
    image: p6
    entrypoint: ["sh", "-c", "./spark-3.2.2-bin-hadoop3.2/sbin/start-master.sh; tail -f /spark-3.2.2-bin-hadoop3.2/logs/*.out"]

  spark-worker:
    image: p6
    entrypoint: ["sh", "-c", "./spark-3.2.2-bin-hadoop3.2/sbin/start-worker.sh spark://spark-boss:7077 -c 1 -m 512M; tail -f /spark-3.2.2-bin-hadoop3.2/logs/*.out"]

  # adapted from here: https://github.com/confluentinc/kafka-images/blob/master/examples/kafka-single-node/docker-compose.yml
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
