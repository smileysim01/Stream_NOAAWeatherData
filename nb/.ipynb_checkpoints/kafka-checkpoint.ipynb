{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff81adea-ef68-4e86-8eee-fa9292fd2b71",
   "metadata": {},
   "source": [
    "# simran4@wisc.edu, rgundavarapu@wisc.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44722ef8-f67f-47c2-82b2-9d46450fad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, time, random, string\n",
    "\n",
    "def one_station(name):\n",
    "    # temp pattern\n",
    "    month_avg = [27,31,44,58,70,79,83,81,74,61,46,32]\n",
    "    shift = (random.random()-0.5) * 30\n",
    "    month_avg = [m + shift + (random.random()-0.5) * 5 for m in month_avg]\n",
    "    \n",
    "    # rain pattern\n",
    "    start_rain = [0.1,0.1,0.3,0.5,0.4,0.2,0.2,0.1,0.2,0.2,0.2,0.1]\n",
    "    shift = (random.random()-0.5) * 0.1\n",
    "    start_rain = [r + shift + (random.random() - 0.5) * 0.2 for r in start_rain]\n",
    "    stop_rain = 0.2 + random.random() * 0.2\n",
    "\n",
    "    # day's state\n",
    "    today = datetime.date(2000, 1, 1)\n",
    "    temp = month_avg[0]\n",
    "    raining = False\n",
    "    \n",
    "    # gen weather\n",
    "    while True:\n",
    "        # choose temp+rain\n",
    "        month = today.month - 1\n",
    "        temp = temp * 0.8 + month_avg[month] * 0.2 + (random.random()-0.5) * 20\n",
    "        if temp < 32:\n",
    "            raining=False\n",
    "        elif raining and random.random() < stop_rain:\n",
    "            raining = False\n",
    "        elif not raining and random.random() < start_rain[month]:\n",
    "            raining = True\n",
    "\n",
    "        yield (today.strftime(\"%Y-%m-%d\"), name, temp, raining)\n",
    "\n",
    "        # next day\n",
    "        today += datetime.timedelta(days=1)\n",
    "        \n",
    "def all_stations(count=10, sleep_sec=1):\n",
    "    assert count <= 26\n",
    "    stations = []\n",
    "    for name in string.ascii_uppercase[:count]:\n",
    "        stations.append(one_station(name))\n",
    "    while True:\n",
    "        for station in stations:\n",
    "            yield next(station)\n",
    "        time.sleep(sleep_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a617bb72-084c-46a2-a2df-1f041e36ec92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stations-json', 'stations', '__consumer_offsets']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kafka import KafkaAdminClient, KafkaProducer, KafkaConsumer, TopicPartition\n",
    "from kafka.admin import NewTopic\n",
    "from kafka.errors import TopicAlreadyExistsError, UnknownTopicOrPartitionError\n",
    "\n",
    "broker = \"kafka:9092\"\n",
    "admin = KafkaAdminClient(bootstrap_servers =[broker])\n",
    "try:\n",
    "    admin.delete_topics([\"stations\", \"stations-json\"])\n",
    "    print(\"deleted\")\n",
    "except UnknownTopicOrPartitionError:\n",
    "    print(\"cannot delete (may not exist yet)\")\n",
    "\n",
    "time.sleep(1)\n",
    "admin.create_topics([NewTopic(\"stations\", 6, 1)])\n",
    "admin.create_topics([NewTopic(\"stations-json\", 6, 1)])\n",
    "admin.list_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de1c4fd-f121-437d-b8a6-949c0520550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from message_pb2 import *\n",
    "from threading import Thread\n",
    "import threading,json\n",
    "def produce():\n",
    "    producer = KafkaProducer(bootstrap_servers=[\"kafka:9092\"],retries=10,acks=-1)\n",
    "    \n",
    "    for date, station, degrees, raining in all_stations(15):\n",
    "        #print(date, station, degrees, raining)\n",
    "        s = Report(date=date, station=station,degrees=(degrees),raining=raining)\n",
    "        value = s.SerializeToString()\n",
    "        key=station.encode('utf-8')\n",
    "        producer.send('stations',key=key ,value=value)\n",
    "        value_json = {\"date\": date, \"station\": station,'degrees':(degrees),'raining':int(raining)}\n",
    "        value_json = bytes(json.dumps(value_json), \"utf-8\")\n",
    "        producer.send('stations-json',key=key,value=value_json)\n",
    "        # TODO: send to \"stations\" stream using protobuf\n",
    "        # TODO: send to \"stations-json\" using JSON\n",
    "\n",
    "# TODO: start thread to run produce\n",
    "threading.Thread(target=produce).start()\n",
    "# never join thread because we want it to run forever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1a3a46-f8d2-4867-8fb4-38efecec8f40",
   "metadata": {},
   "source": [
    "## PART 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b559f96-7419-415c-85f7-efb05f9e34fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "for partition in range(6):\n",
    "    path = f\"partition-{partition}.json\"\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6931146-95a3-420c-ae4f-b8da3f02b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_partition(partition_num):\n",
    "    path = f\"partition-{partition_num}.json\"\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as file:\n",
    "            return json.load(file)\n",
    "    else:\n",
    "        return {'partition':partition_num}\n",
    "\n",
    "def save_partition(partition):\n",
    "    path = f\"partition-{partition['partition']}.json\"\n",
    "    with open(path, \"w\") as file:\n",
    "        json.dump(partition, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82fbf320-4ccb-48de-8e6d-01fa7b57d332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUND 0\n",
      "exiting\n",
      "exiting\n",
      "exiting\n",
      "ROUND 1\n",
      "exiting\n",
      "exiting\n",
      "exiting\n"
     ]
    }
   ],
   "source": [
    "def consume(part_nums=[], iterations=10):\n",
    "    consumer = KafkaConsumer(bootstrap_servers=[broker])\n",
    "    # TODO: create list of TopicPartition objects\n",
    "    partition_objs=[TopicPartition('stations',part_num) for part_num in part_nums]\n",
    "    consumer.assign(partition_objs)\n",
    "    partitions={}\n",
    "    # PART 1: initialization\n",
    "    for part_num in part_nums:\n",
    "        partitions['partition']=load_partition(part_num)['partition'] # key=partition num, value=snapshot dict\n",
    "        if 'offset' in partitions.keys():\n",
    "            consumer.seek(TopicPartition('stations',part_num),partitions['offset'])\n",
    "        else:\n",
    "            consumer.seek_to_beginning(TopicPartition('stations',part_num)) # else\n",
    "        counter=1\n",
    "        for i in range(iterations):\n",
    "            batch = consumer.poll(1000) # 1s timeout\n",
    "            date_list=[]\n",
    "            for tp, messages in batch.items():\n",
    "                for msg in messages:\n",
    "                    s = Report.FromString(msg.value)\n",
    "                    date_list.append(s.date)\n",
    "                    if s.station in partitions.keys():\n",
    "                        if s.date<=partitions[s.station]['end']:\n",
    "                            break\n",
    "                            break\n",
    "                        partitions[s.station]['sum']+=s.degrees\n",
    "                        partitions[s.station]['count']+=1\n",
    "                        partitions[s.station]['avg']=(partitions[s.station]['sum']/partitions[s.station]['count'])\n",
    "                        partitions[s.station]['start']=s.date if s.date<partitions[s.station]['start'] else partitions[s.station]['start']\n",
    "                        partitions[s.station]['end']=s.date\n",
    "                    else:\n",
    "                        partitions[s.station]={}\n",
    "                        partitions[s.station]['sum']=s.degrees\n",
    "                        partitions[s.station]['count']=0\n",
    "                        partitions[s.station]['avg']=0\n",
    "                        partitions[s.station]['start']=s.date\n",
    "                        partitions[s.station]['end']=s.date\n",
    "\n",
    "                    partitions['offset']=consumer.position(tp)\n",
    "                    save_partition(partitions)\n",
    "    print(\"exiting\")\n",
    "\n",
    "for i in range(2):\n",
    "    print(\"ROUND\", i)\n",
    "    t1 = threading.Thread(target=consume, args=([0,1], 30))\n",
    "    t2 = threading.Thread(target=consume, args=([2,3], 30))\n",
    "    t3 = threading.Thread(target=consume, args=([4,5], 30))\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    t3.start()\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "    t3.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab6fb81-9545-43d8-b93b-a52ac21a5f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"partition\": 0, \"N\": {\"sum\": 2883.689837136271, \"count\": 81, \"avg\": 35.601109100447786, \"start\": \"2000-01-01\", \"end\": \"2000-03-22\"}, \"offset\": 82, \"E\": {\"sum\": 1099.4364423101094, \"count\": 23, \"avg\": 47.80158444826563, \"start\": \"2000-02-28\", \"end\": \"2000-03-22\"}, \"O\": {\"sum\": 1204.1335320732219, \"count\": 23, \"avg\": 52.35363182927052, \"start\": \"2000-02-28\", \"end\": \"2000-03-22\"}}{\"partition\": 1, \"N\": {\"sum\": 4264.90735980181, \"count\": 108, \"avg\": 39.489882961127876, \"start\": \"2000-01-01\", \"end\": \"2000-04-18\"}, \"offset\": 218, \"E\": {\"sum\": 2774.8516013997323, \"count\": 50, \"avg\": 55.49703202799465, \"start\": \"2000-02-28\", \"end\": \"2000-04-18\"}, \"O\": {\"sum\": 2876.1479630908193, \"count\": 50, \"avg\": 57.52295926181639, \"start\": \"2000-02-28\", \"end\": \"2000-04-18\"}}{\"partition\": 2, \"F\": {\"sum\": 2285.590579688906, \"count\": 82, \"avg\": 27.87305584986471, \"start\": \"2000-01-01\", \"end\": \"2000-03-23\"}, \"offset\": 249, \"I\": {\"sum\": 1808.696662946616, \"count\": 82, \"avg\": 22.057276377397756, \"start\": \"2000-01-01\", \"end\": \"2000-03-23\"}, \"J\": {\"sum\": 3615.0573406531107, \"count\": 82, \"avg\": 44.08606512991599, \"start\": \"2000-01-01\", \"end\": \"2000-03-23\"}, \"D\": {\"sum\": 1373.9086541390939, \"count\": 24, \"avg\": 57.24619392246225, \"start\": \"2000-02-28\", \"end\": \"2000-03-23\"}, \"G\": {\"sum\": 940.1015161895166, \"count\": 24, \"avg\": 39.17089650789652, \"start\": \"2000-02-28\", \"end\": \"2000-03-23\"}, \"M\": {\"sum\": 1089.0740801620736, \"count\": 24, \"avg\": 45.37808667341974, \"start\": \"2000-02-28\", \"end\": \"2000-03-23\"}}{\"partition\": 3, \"F\": {\"sum\": 3617.2338839405256, \"count\": 109, \"avg\": 33.185631962757114, \"start\": \"2000-01-01\", \"end\": \"2000-04-19\"}, \"offset\": 330, \"I\": {\"sum\": 3001.04165023196, \"count\": 109, \"avg\": 27.532492203962935, \"start\": \"2000-01-01\", \"end\": \"2000-04-19\"}, \"J\": {\"sum\": 5329.683690328097, \"count\": 109, \"avg\": 48.8961806452119, \"start\": \"2000-01-01\", \"end\": \"2000-04-19\"}, \"D\": {\"sum\": 2912.83356761787, \"count\": 51, \"avg\": 57.11438367878176, \"start\": \"2000-02-28\", \"end\": \"2000-04-19\"}, \"G\": {\"sum\": 2356.7877854915873, \"count\": 51, \"avg\": 46.2115252057174, \"start\": \"2000-02-28\", \"end\": \"2000-04-19\"}, \"M\": {\"sum\": 2534.845157313282, \"count\": 51, \"avg\": 49.702846221829056, \"start\": \"2000-02-28\", \"end\": \"2000-04-19\"}}{\"partition\": 4, \"A\": {\"sum\": 3797.9538508453056, \"count\": 83, \"avg\": 45.758480130666335, \"start\": \"2000-01-01\", \"end\": \"2000-03-24\"}, \"offset\": 84, \"B\": {\"sum\": 1777.6985796788763, \"count\": 83, \"avg\": 21.41805517685393, \"start\": \"2000-01-01\", \"end\": \"2000-03-24\"}, \"C\": {\"sum\": 1778.2606182668248, \"count\": 83, \"avg\": 21.424826726106325, \"start\": \"2000-01-01\", \"end\": \"2000-03-24\"}, \"K\": {\"sum\": 3893.4320624669867, \"count\": 83, \"avg\": 46.90882002972273, \"start\": \"2000-01-01\", \"end\": \"2000-03-24\"}, \"L\": {\"sum\": 3443.36477169706, \"count\": 83, \"avg\": 41.48632255056699, \"start\": \"2000-01-01\", \"end\": \"2000-03-24\"}, \"H\": {\"sum\": 1282.8370351239062, \"count\": 25, \"avg\": 51.31348140495625, \"start\": \"2000-02-28\", \"end\": \"2000-03-24\"}}{\"partition\": 5, \"A\": {\"sum\": 5753.652146375513, \"count\": 110, \"avg\": 52.30592860341376, \"start\": \"2000-01-01\", \"end\": \"2000-04-20\"}, \"offset\": 111, \"B\": {\"sum\": 3203.581153236568, \"count\": 110, \"avg\": 29.123465029423343, \"start\": \"2000-01-01\", \"end\": \"2000-04-20\"}, \"C\": {\"sum\": 3375.571175165502, \"count\": 110, \"avg\": 30.687010683322747, \"start\": \"2000-01-01\", \"end\": \"2000-04-20\"}, \"K\": {\"sum\": 5620.6531879744425, \"count\": 110, \"avg\": 51.09684716340402, \"start\": \"2000-01-01\", \"end\": \"2000-04-20\"}, \"L\": {\"sum\": 4938.359571038104, \"count\": 110, \"avg\": 44.89417791852822, \"start\": \"2000-01-01\", \"end\": \"2000-04-20\"}, \"H\": {\"sum\": 2962.4038026665203, \"count\": 52, \"avg\": 56.96930389743308, \"start\": \"2000-02-28\", \"end\": \"2000-04-20\"}}"
     ]
    }
   ],
   "source": [
    "!cat partition*.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526e5e33-6373-4b42-b230-56637178f0f4",
   "metadata": {},
   "source": [
    "part_nums=[0,1]\n",
    "consumer = KafkaConsumer(bootstrap_servers=[broker])\n",
    "# TODO: create list of TopicPartition objects\n",
    "partition_objs=[TopicPartition('stations',part_num) for part_num in part_nums]\n",
    "consumer.assign(partition_objs)\n",
    "partitions={}\n",
    "counter=1\n",
    "print(consumer.assignment())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18485575-6969-4fbd-8646-62477b066fa8",
   "metadata": {},
   "source": [
    "for i in part_nums:\n",
    "    partitions['partition']=load_partition(i)['partition'] # key=partition num, value=snapshot dict\n",
    "    if 'offset' in partitions.keys():\n",
    "        print('loading previous offset')\n",
    "        print('PARTITION: ',i)\n",
    "        consumer.seek(TopicPartition('stations',i),partitions['offset'])\n",
    "    else:\n",
    "        print('NEW READ , ',i)\n",
    "        consumer.seek_to_beginning(TopicPartition('stations',i)) # else\n",
    "    batch = consumer.poll(1000)\n",
    "    date_list=[]\n",
    "    for tp, messages in batch.items():\n",
    "        print(tp)\n",
    "        for msg in messages:\n",
    "            s = Report.FromString(msg.value)\n",
    "            date_list.append(s.date)\n",
    "            #print(s.station)\n",
    "            if s.station in partitions.keys():\n",
    "                if s.date<=partitions[s.station]['end']:\n",
    "                    break\n",
    "                counter+=1\n",
    "                partitions[s.station]['sum']+=s.degrees\n",
    "                partitions[s.station]['count']+=1\n",
    "                partitions[s.station]['avg']=(partitions[s.station]['sum']/counter)\n",
    "                partitions[s.station]['start'] = s.date if s.date<partitions[s.station]['start'] else partitions[s.station]['start']\n",
    "                partitions[s.station]['end']=s.date\n",
    "            else:\n",
    "                partitions[s.station]={}\n",
    "                partitions[s.station]['sum']=s.degrees\n",
    "                partitions[s.station]['count']=counter\n",
    "                partitions[s.station]['avg']=0\n",
    "                partitions[s.station]['start']=s.date\n",
    "                partitions[s.station]['end']=s.date\n",
    "\n",
    "        partitions['offset']=consumer.position(tp)\n",
    "        save_partition(partitions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
