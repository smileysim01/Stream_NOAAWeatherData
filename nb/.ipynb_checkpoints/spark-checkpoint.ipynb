{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633b0732-969a-4967-82a5-eaca99fb212e",
   "metadata": {},
   "source": [
    "# simran4@wisc.edu, rgundavarapu@wisc.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c4a525-3c92-4df3-a6bf-8d3eb5b6a67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.10/dist-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-d5d19e2d-9bde-476f-ae83-6388f6c16ef4;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.2.2 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.2.2 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.8.1 in central\n",
      "\tfound org.lz4#lz4-java;1.7.1 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.1 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.1 in central\n",
      "\tfound org.apache.htrace#htrace-core4;4.1.0-incubating in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",
      "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.2.2/spark-sql-kafka-0-10_2.12-3.2.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.2.2!spark-sql-kafka-0-10_2.12.jar (40ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.2.2/spark-token-provider-kafka-0-10_2.12-3.2.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.2.2!spark-token-provider-kafka-0-10_2.12.jar (17ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/2.8.1/kafka-clients-2.8.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.kafka#kafka-clients;2.8.1!kafka-clients.jar (240ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.0!jsr305.jar (17ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.6.2/commons-pool2-2.6.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.commons#commons-pool2;2.6.2!commons-pool2.jar (18ms)\n",
      "downloading https://repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar ...\n",
      "\t[SUCCESSFUL ] org.spark-project.spark#unused;1.0.0!unused.jar (13ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-client-runtime;3.3.1!hadoop-client-runtime.jar (592ms)\n",
      "downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar ...\n",
      "\t[SUCCESSFUL ] org.lz4#lz4-java;1.7.1!lz4-java.jar (22ms)\n",
      "downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.8.4/snappy-java-1.1.8.4.jar ...\n",
      "\t[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.8.4!snappy-java.jar(bundle) (39ms)\n",
      "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar ...\n",
      "\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.30!slf4j-api.jar (15ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-api/3.3.1/hadoop-client-api-3.3.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-client-api;3.3.1!hadoop-client-api.jar (282ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.htrace#htrace-core4;4.1.0-incubating!htrace-core4.jar (39ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar ...\n",
      "\t[SUCCESSFUL ] commons-logging#commons-logging;1.1.3!commons-logging.jar (15ms)\n",
      ":: resolution report :: resolve 7078ms :: artifacts dl 1381ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.1 from central in [default]\n",
      "\torg.apache.htrace#htrace-core4;4.1.0-incubating from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.8.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.2.2 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.2.2 from central in [default]\n",
      "\torg.lz4#lz4-java;1.7.1 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.4 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   13  |   13  |   13  |   0   ||   13  |   13  |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-d5d19e2d-9bde-476f-ae83-6388f6c16ef4\n",
      "\tconfs: [default]\n",
      "\t13 artifacts copied, 0 already retrieved (59188kB/183ms)\n",
      "23/04/29 23:17:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder.appName(\"cs544\")\n",
    "         .config(\"spark.sql.shuffle.partitions\", 10)\n",
    "         .config(\"spark.ui.showConsoleProgress\", False)\n",
    "         .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.2')\n",
    "         .getOrCreate())\n",
    "\n",
    "df = (\n",
    "    spark.readStream.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\")\n",
    "    .option(\"subscribe\", \"stations-json\")\n",
    "    .option(\"startingOffsets\", \"earliest\")\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de5a102-bc22-42c4-9982-9ecaf93ea31c",
   "metadata": {},
   "source": [
    "Use a spark.readStream to load the stations-json stream to a DataFrame. Tips:\n",
    "\n",
    "the value comments will contain the bytes you wrote. You can use col(????).cast(\"string\") to convert bytes to a string (this assumes UTF-8 encoding)\n",
    "you can convert a JSON string to a structure using from_json(????, schema). The schema needs to specify the types. It will be something like schema = \"station STRING, date DATE, ...\" for you.\n",
    "if a column named \"value\" is a struct, you can access an entry named \"station\" inside with \"value.station\"\n",
    "Requirements\n",
    "\n",
    "use .option(\"startingOffsets\",\"earliest\") to begin with the earliest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e687ad-e747-43ec-978d-e910652b7596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7782d3ea-3b16-43f9-83a3-aef4f2c95afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/29 23:22:23 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-8bceda1a-d026-4598-87b8-da795fe2a340. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/04/29 23:22:23 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "|station|     start|       end|measurements|               avg|               max|\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "|      A|2000-01-01|2001-03-24|         449| 50.90866728496191|    95.46900798609|\n",
      "|      B|2000-01-01|2001-03-24|         449| 64.81959401594443|108.50507875790866|\n",
      "|      C|2000-01-01|2001-03-24|         449| 55.52640827473621|106.10702325619066|\n",
      "|      D|2000-01-01|2001-03-24|         449| 56.12941641124775| 101.1477740552954|\n",
      "|      E|2000-01-01|2001-03-24|         449|  46.0631829099098| 92.20855796008401|\n",
      "|      F|2000-01-01|2001-03-24|         449| 45.04384583330344|  96.4259411047491|\n",
      "|      G|2000-01-01|2001-03-24|         449|51.770040761033755|  98.9415104349403|\n",
      "|      H|2000-01-01|2001-03-24|         449| 63.78550198502119|117.32776920148245|\n",
      "|      I|2000-01-01|2001-03-24|         449| 53.54565916067302| 97.73809408254385|\n",
      "|      J|2000-01-01|2001-03-24|         449| 47.46442850565543|  92.0109804961719|\n",
      "|      K|2000-01-01|2001-03-24|         449| 51.61670878864353| 99.48162353097176|\n",
      "|      L|2000-01-01|2001-03-24|         449|38.662273995059465| 84.42477238667219|\n",
      "|      M|2000-01-01|2001-03-24|         449| 53.31847020951772|105.77726253361114|\n",
      "|      N|2000-01-01|2001-03-24|         449| 37.76471109115572| 89.62166398780715|\n",
      "|      O|2000-01-01|2001-03-24|         449| 38.71745448355427| 85.81184419867523|\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/29 23:22:29 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 5000 milliseconds, but spent 6612 milliseconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "|station|     start|       end|measurements|               avg|               max|\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "|      A|2000-01-01|2001-03-27|         452|  50.7552636899818|    95.46900798609|\n",
      "|      B|2000-01-01|2001-03-27|         452|  64.8411688292597|108.50507875790866|\n",
      "|      C|2000-01-01|2001-03-27|         452| 55.52237275615748|106.10702325619066|\n",
      "|      D|2000-01-01|2001-03-27|         452|56.114228658236186| 101.1477740552954|\n",
      "|      E|2000-01-01|2001-03-27|         452|46.046550453576344| 92.20855796008401|\n",
      "|      F|2000-01-01|2001-03-27|         452|44.993332951515285|  96.4259411047491|\n",
      "|      G|2000-01-01|2001-03-27|         452| 51.70278176541843|  98.9415104349403|\n",
      "|      H|2000-01-01|2001-03-27|         452| 63.76886179897437|117.32776920148245|\n",
      "|      I|2000-01-01|2001-03-27|         452| 53.46156449591859| 97.73809408254385|\n",
      "|      J|2000-01-01|2001-03-27|         452| 47.51801276230797|  92.0109804961719|\n",
      "|      K|2000-01-01|2001-03-27|         452| 51.50673087703482| 99.48162353097176|\n",
      "|      L|2000-01-01|2001-03-27|         452|  38.6583441973764| 84.42477238667219|\n",
      "|      M|2000-01-01|2001-03-27|         452| 53.21113130613922|105.77726253361114|\n",
      "|      N|2000-01-01|2001-03-27|         452| 37.76271132152685| 89.62166398780715|\n",
      "|      O|2000-01-01|2001-03-27|         452|38.622053566285054| 85.81184419867523|\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "|station|     start|       end|measurements|               avg|               max|\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "|      A|2000-01-01|2001-03-31|         456|50.609988349169946|    95.46900798609|\n",
      "|      B|2000-01-01|2001-03-31|         456| 64.80067785497125|108.50507875790866|\n",
      "|      C|2000-01-01|2001-03-31|         456|  55.5915245695281|106.10702325619066|\n",
      "|      D|2000-01-01|2001-03-31|         456| 56.09403130574698| 101.1477740552954|\n",
      "|      E|2000-01-01|2001-03-31|         456| 46.07418398692982| 92.20855796008401|\n",
      "|      F|2000-01-01|2001-03-31|         456| 44.91373779946651|  96.4259411047491|\n",
      "|      G|2000-01-01|2001-03-31|         456| 51.66738918473094|  98.9415104349403|\n",
      "|      H|2000-01-01|2001-03-31|         456|63.720557932015296|117.32776920148245|\n",
      "|      I|2000-01-01|2001-03-31|         456|53.257436273832724| 97.73809408254385|\n",
      "|      J|2000-01-01|2001-03-31|         456| 47.62323619839658|  92.0109804961719|\n",
      "|      K|2000-01-01|2001-03-31|         456| 51.38121128527971| 99.48162353097176|\n",
      "|      L|2000-01-01|2001-03-31|         456| 38.59799803181314| 84.42477238667219|\n",
      "|      M|2000-01-01|2001-03-31|         456| 53.18518877383421|105.77726253361114|\n",
      "|      N|2000-01-01|2001-03-31|         456| 37.72814480679237| 89.62166398780715|\n",
      "|      O|2000-01-01|2001-03-31|         456|  38.3759282285961| 85.81184419867523|\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "|station|     start|       end|measurements|               avg|               max|\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "|      A|2000-01-01|2001-04-03|         459| 50.54909518228406|    95.46900798609|\n",
      "|      B|2000-01-01|2001-04-03|         459|  64.7744947281476|108.50507875790866|\n",
      "|      C|2000-01-01|2001-04-03|         459|55.617142239365535|106.10702325619066|\n",
      "|      D|2000-01-01|2001-04-03|         459| 56.09969116228724| 101.1477740552954|\n",
      "|      E|2000-01-01|2001-04-03|         459| 46.01256461263248| 92.20855796008401|\n",
      "|      F|2000-01-01|2001-04-03|         459|44.868803070288344|  96.4259411047491|\n",
      "|      G|2000-01-01|2001-04-03|         459|51.727226562260604|  98.9415104349403|\n",
      "|      H|2000-01-01|2001-04-03|         459|63.640877234530855|117.32776920148245|\n",
      "|      I|2000-01-01|2001-04-03|         459| 53.21212445888679| 97.73809408254385|\n",
      "|      J|2000-01-01|2001-04-03|         459| 47.73990452913567|  92.0109804961719|\n",
      "|      K|2000-01-01|2001-04-03|         459| 51.44031445901178| 99.48162353097176|\n",
      "|      L|2000-01-01|2001-04-03|         459|  38.5866848802614| 84.42477238667219|\n",
      "|      M|2000-01-01|2001-04-03|         459| 53.26366189501414|105.77726253361114|\n",
      "|      N|2000-01-01|2001-04-03|         459|37.703344221762435| 89.62166398780715|\n",
      "|      O|2000-01-01|2001-04-03|         459| 38.36558668950037| 85.81184419867523|\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "|station|     start|       end|measurements|               avg|               max|\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "|      A|2000-01-01|2001-04-07|         463| 50.50336828361988|    95.46900798609|\n",
      "|      B|2000-01-01|2001-04-07|         463| 64.79834488994346|108.50507875790866|\n",
      "|      C|2000-01-01|2001-04-07|         463| 55.59348560008963|106.10702325619066|\n",
      "|      D|2000-01-01|2001-04-07|         463| 56.11344256193718| 101.1477740552954|\n",
      "|      E|2000-01-01|2001-04-07|         463|  45.9656962887875| 92.20855796008401|\n",
      "|      F|2000-01-01|2001-04-07|         463| 44.81205303004185|  96.4259411047491|\n",
      "|      G|2000-01-01|2001-04-07|         463|51.764655126028664|  98.9415104349403|\n",
      "|      H|2000-01-01|2001-04-07|         463|63.643540414215025|117.32776920148245|\n",
      "|      I|2000-01-01|2001-04-07|         463| 53.10359572571786| 97.73809408254385|\n",
      "|      J|2000-01-01|2001-04-07|         463|  47.7497559244459|  92.0109804961719|\n",
      "|      K|2000-01-01|2001-04-07|         463| 51.51512574978773| 99.48162353097176|\n",
      "|      L|2000-01-01|2001-04-07|         463|38.556618209957904| 84.42477238667219|\n",
      "|      M|2000-01-01|2001-04-07|         463| 53.40261042474896|105.77726253361114|\n",
      "|      N|2000-01-01|2001-04-07|         463|37.762166935585675| 89.62166398780715|\n",
      "|      O|2000-01-01|2001-04-07|         463| 38.44313708233704| 85.81184419867523|\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 5\n",
      "-------------------------------------------\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "|station|     start|       end|measurements|               avg|               max|\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "|      A|2000-01-01|2001-04-11|         467|   50.504731589639|    95.46900798609|\n",
      "|      B|2000-01-01|2001-04-11|         467| 64.82238583624428|108.50507875790866|\n",
      "|      C|2000-01-01|2001-04-11|         467|  55.5491644974559|106.10702325619066|\n",
      "|      D|2000-01-01|2001-04-11|         467|56.083400049919234| 101.1477740552954|\n",
      "|      E|2000-01-01|2001-04-11|         467|46.068257830666525| 92.20855796008401|\n",
      "|      F|2000-01-01|2001-04-11|         467| 44.82186508848851|  96.4259411047491|\n",
      "|      G|2000-01-01|2001-04-11|         467|51.714028698535756|  98.9415104349403|\n",
      "|      H|2000-01-01|2001-04-11|         467|  63.6596720407449|117.32776920148245|\n",
      "|      I|2000-01-01|2001-04-11|         467|53.082630080877905| 97.73809408254385|\n",
      "|      J|2000-01-01|2001-04-11|         467| 47.70218558751431|  92.0109804961719|\n",
      "|      K|2000-01-01|2001-04-11|         467| 51.55670636953451| 99.48162353097176|\n",
      "|      L|2000-01-01|2001-04-11|         467| 38.59474517204859| 84.42477238667219|\n",
      "|      M|2000-01-01|2001-04-11|         467| 53.54307787564766|105.77726253361114|\n",
      "|      N|2000-01-01|2001-04-11|         467| 37.83085014253955| 89.62166398780715|\n",
      "|      O|2000-01-01|2001-04-11|         467|38.525082220246645| 85.81184419867523|\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 6\n",
      "-------------------------------------------\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "|station|     start|       end|measurements|               avg|               max|\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "|      A|2000-01-01|2001-04-16|         472| 50.57720287294635|    95.46900798609|\n",
      "|      B|2000-01-01|2001-04-16|         472| 64.96682264052593|108.50507875790866|\n",
      "|      C|2000-01-01|2001-04-16|         472| 55.57561995821106|106.10702325619066|\n",
      "|      D|2000-01-01|2001-04-16|         472| 56.06136355209162| 101.1477740552954|\n",
      "|      E|2000-01-01|2001-04-16|         472|46.219259149652714| 92.20855796008401|\n",
      "|      F|2000-01-01|2001-04-16|         472|44.838647985255314|  96.4259411047491|\n",
      "|      G|2000-01-01|2001-04-16|         472| 51.70526151806306|  98.9415104349403|\n",
      "|      H|2000-01-01|2001-04-16|         472|63.759712437163074|117.32776920148245|\n",
      "|      I|2000-01-01|2001-04-16|         472| 53.33889966237696| 97.73809408254385|\n",
      "|      J|2000-01-01|2001-04-16|         472| 47.66075301689015|  92.0109804961719|\n",
      "|      K|2000-01-01|2001-04-16|         472| 51.65367392793725| 99.48162353097176|\n",
      "|      L|2000-01-01|2001-04-16|         472| 38.76461895230621| 84.42477238667219|\n",
      "|      M|2000-01-01|2001-04-16|         472|53.633349401904056|105.77726253361114|\n",
      "|      N|2000-01-01|2001-04-16|         472|37.946943045873475| 89.62166398780715|\n",
      "|      O|2000-01-01|2001-04-16|         472|38.752972309177125| 85.81184419867523|\n",
      "+-------+----------+----------+------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions\n",
    "schema = \"station STRING, date DATE, degrees DOUBLE, raining INTEGER\"\n",
    "data = (df.select(col(\"key\").cast(\"string\"),\n",
    "          from_json(col(\"value\").cast(\"string\"), schema).alias(\"value\")))\n",
    "\n",
    "counts_df = data.groupBy('value.station').agg(functions.min('value.date').alias('start'),\n",
    "                                              functions.max('value.date').alias('end'),\n",
    "                                              functions.count('value.station').alias('measurements'),\n",
    "                                              functions.avg('value.degrees').alias('avg'),\n",
    "                                              functions. max('value.degrees').alias('max')).sort('value.station')\n",
    "                 \n",
    "s = counts_df.writeStream.format(\"console\").trigger(processingTime=\"5 seconds\").outputMode(\"complete\").start()\n",
    "s.awaitTermination(30)\n",
    "s.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b68be55-5e05-47b3-a768-32d96b543860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
